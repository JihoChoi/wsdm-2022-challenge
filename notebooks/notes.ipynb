{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3241b9c6-a7a9-4f27-9de3-960975df2b89",
   "metadata": {},
   "source": [
    "### EDA# EDA\n",
    "\n",
    "\n",
    "### Datasets\n",
    "* Dataset A: a dynamic event graph with entities as nodes and different types of events as edges.\n",
    "* Dataset B: a user-item graph with users and items as nodes and different types of interactions as edges.\n",
    "* Train\n",
    "    * Dataset A\n",
    "        * edges_train_A.csv\n",
    "            * src_id -> dst_id, edge_type, timestamp\n",
    "        * node_features.csv\n",
    "            * node_id, anonymized categorical features\n",
    "        * edge_type_features.csv\n",
    "            * edge_id, anonymized categorical features\n",
    "    * Dataset B\n",
    "        * edges_train_B.csv\n",
    "            * src_id -> dst_id, edge_type, timestamp, feat (anonymized edge features)\n",
    "* Test\n",
    "    * Dataset A / Dataset B\n",
    "        * src_id -> dst_id, edge_type, start_time, end_time\n",
    "\n",
    "\n",
    "### References\n",
    "* https://networkx.org/documentation/stable/reference/readwrite/edgelist.html\n",
    "* https://towardsdatascience.com/pyvis-visualize-interactive-network-graphs-in-python-77e059791f01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba8b75-3a1e-4798-b136-541809c441f1",
   "metadata": {},
   "source": [
    "### TODOs\n",
    "- [X] 날짜별 노드 종류 분포 (histogram)\n",
    "- [ ] 두 노드 사이의 edge 수 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f595b35-0016-4d6f-8fd6-7b6ae1e2210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b91c4252-86e3-4cd9-8f04-145ce792d5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nedge_list = pd.read_csv(\\n    f\"{DATA_DIR}/train/edges_train_A.csv\",\\n    header=None,\\n    names=[\\'src_id\\', \\'dst_id\\', \\'edge_type\\', \\'timestamp\\'],\\n    dtype={\\'src_id\\': int, \\'dst_id\\': int, \\'edge_type\\': int, \\'timestamp\\': int},\\n).sort_values(\\'timestamp\\')\\n\\nedge_list[\\'datetime\\'] = edge_list[\\'timestamp\\'].copy().apply(\\n    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d_%H%M%S\")\\n)\\nedge_list[\\'month\\'] = edge_list[\\'timestamp\\'].apply(\\n    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m\")\\n)\\nedge_list[\\'date\\'] = edge_list[\\'timestamp\\'].apply(\\n    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d\")\\n)\\n\\nsave_pickle_file(f\"{DATA_DIR}/train/edges_train_A_cache.pickle\", edge_list)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "2022-01-00\n",
    "author: Jiho Choi\n",
    "\n",
    "References\n",
    "    - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import download_url, InMemoryDataset\n",
    "from torch_geometric.loader import GraphSAINTRandomWalkSampler\n",
    "\n",
    "\n",
    "\n",
    "# from parse_args import params\n",
    "sys.path.append('../scripts/')\n",
    "from utils import label_stats\n",
    "from utils import load_pickle_file\n",
    "from utils import save_pickle_file\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "DATA_DIR = \"../data/wsdm-2022\"\n",
    "\"\"\"\n",
    "edge_list = pd.read_csv(\n",
    "    f\"{DATA_DIR}/train/edges_train_A.csv\",\n",
    "    header=None,\n",
    "    names=['src_id', 'dst_id', 'edge_type', 'timestamp'],\n",
    "    dtype={'src_id': int, 'dst_id': int, 'edge_type': int, 'timestamp': int},\n",
    ").sort_values('timestamp')\n",
    "\n",
    "edge_list['datetime'] = edge_list['timestamp'].copy().apply(\n",
    "    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "edge_list['month'] = edge_list['timestamp'].apply(\n",
    "    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m\")\n",
    ")\n",
    "edge_list['date'] = edge_list['timestamp'].apply(\n",
    "    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d\")\n",
    ")\n",
    "\n",
    "save_pickle_file(f\"{DATA_DIR}/train/edges_train_A_cache.pickle\", edge_list)\n",
    "\"\"\"\n",
    "# edge_list_df = load_pickle_file(f\"{DATA_DIR}/train/edges_train_A_cache.pickle\")\n",
    "# grouped_df = edge_list_df.groupby('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4207ec1-f0dc-4d9c-8e3f-0cde487d5f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4b78e0-a13a-4a29-b4a4-3be62e51847b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(100)\n",
    "print(a.shape)\n",
    "b = torch.rand(100)\n",
    "print(b.shape)\n",
    "# b = b.unsqueeze(0)\n",
    "print(b.shape)\n",
    "c = torch.cat([a, b], dim=0)\n",
    "c = torch.stack([a, b], dim=0)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb97f4-cdb1-422b-8336-f2d102f42dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb2f7a2-8f52-420a-bf3f-4d31a10236b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/wsdm-2022\"\n",
    "\n",
    "edge_list_df = pd.read_csv(\n",
    "    f\"{DATA_DIR}/raw/train/edges_train_A.csv\",\n",
    "    header=None,\n",
    "    names=['src_id', 'dst_id', 'edge_type', 'timestamp'],\n",
    "    dtype={'src_id': int, 'dst_id': int, 'edge_type': int, 'timestamp': int},\n",
    ").sort_values('timestamp')\n",
    "edge_list_df['date'] = edge_list_df['timestamp'].apply(\n",
    "    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d\")\n",
    ")\n",
    "grouped_df = edge_list_df.groupby('date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd94aa1-489d-48b6-a045-4e25490018f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20141019\n",
      "20170514\n"
     ]
    }
   ],
   "source": [
    "print(list(grouped_df.groups.keys())[0])\n",
    "print(list(grouped_df.groups.keys())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820279b5-6d7a-4a66-8382-514ac930fd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "939it [00:00, 1085870.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "date_start = datetime.strptime(\"20141019\", \"%Y%m%d\")\n",
    "date_end = datetime.strptime(\"20170514\", \"%Y%m%d\")\n",
    "\n",
    "file_name_list = []\n",
    "\n",
    "for index, date in tqdm(enumerate(pd.date_range(date_start, date_end))):\n",
    "    # print(index, date)\n",
    "    file_name_list.append(f'graph_{index}')\n",
    "\n",
    "# for index, date in enumerate(range(date_start, date_end)):\n",
    "#     file_name_list.append(f'graph_{index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c9a25-8079-4914-90b2-f78f46477ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a92437a-554d-4365-b461-896c1ee93a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 16, 32]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"../data/wsdm-2022\"\n",
    "edge_type_features_df = pd.read_csv(\n",
    "    f\"{DATA_DIR}/raw/train/edge_type_features.csv\",\n",
    "    header=None,\n",
    "    names=['edge_type', 'feature1', 'feature2', 'feature3'],\n",
    "    dtype={'edge_type': int, 'feature1': int, 'feature2': int, 'feature3': int},\n",
    ").sort_values('edge_type')\n",
    "# edge_type_features_df\n",
    "\n",
    "edge_type_feature_dict = {}\n",
    "for index, row in enumerate(edge_type_features_df.values.tolist()):\n",
    "    edge_type, feature1, feature2, feature3 = row\n",
    "    edge_type_feature_dict[edge_type] = [feature1, feature2, feature3]\n",
    "edge_type_feature_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "784d9b14-a715-436e-bb67-6e2d780b2d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 56, 16, 32]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_type_features_df[edge_type_features_df['edge_type']==0].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21b9af-84d5-48cd-81d3-73e4d72a65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_type_features.values.tolist()\n",
    "# [0, 56, 16, 32],\n",
    "#  [1, 179, 15, 70],\n",
    "#  [2, 65, 6, 62],\n",
    "#  [3, 104, 12, 86],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c19ea-c1a4-40a5-8022-0db0afac1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_type_features.to_dict('records')\n",
    "# [{'edge_type': 0, 'feature1': 56, 'feature2': 16, 'feature3': 32},\n",
    "#  {'edge_type': 1, 'feature1': 179, 'feature2': 15, 'feature3': 70},\n",
    "#  {'edge_type': 2, 'feature1': 65, 'feature2': 6, 'feature3': 62},\n",
    "#  {'edge_type': 3, 'feature1': 104, 'feature2': 12, 'feature3': 86},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b957b795-8234-4b8b-874b-51a629a14f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e6d4ed2-a3d7-4621-8a06-c0d624350537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "edge_type_features.to_dict('records')\n",
    "\n",
    "edge_type_features = edge_type_features.values.tolist()\n",
    "\n",
    "for edge_type in edge_type_series:\n",
    "    print(edge_type)\n",
    "    break\n",
    "\n",
    "\n",
    "# edge_type_features['edge_type']==edge_type\n",
    "# edge_type_features[].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b0d50-8863-4576-9566-c2ac7d710adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_features[edge_type_features['edge_type']==edge_type].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8883914-cb78-40ec-9907-c5d0a45545d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5de0a9d-5445-4c06-9e86-c65dc6d8ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/wsdm-2022\"\n",
    "\n",
    "import csv\n",
    "\n",
    "node_feature_dict = {}\n",
    "with open(f\"{DATA_DIR}/raw/train/node_features.csv\", mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        row = list(map(lambda x: int(x), row))\n",
    "        node_id, features = row[0], row[1:]\n",
    "        features = list(map(lambda x: x if x != -1 else 0, features))\n",
    "        node_feature_dict[node_id] = features\n",
    "# node_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e77b57b-7ebc-4930-ad66-9d4c8d59a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/wsdm-2022\"\n",
    "\n",
    "node_features_df = pd.read_csv(\n",
    "    f\"{DATA_DIR}/raw/train/node_features.csv\", header=None,\n",
    "    names=[\n",
    "        'node_id',\n",
    "        'feature1', 'feature2', 'feature3', 'feature4',\n",
    "        'feature5', 'feature6', 'feature7', 'feature8'\n",
    "    ],\n",
    "    dtype={\n",
    "        'node_id': int,\n",
    "        'feature1': int, 'feature2': int, 'feature3': int, 'feature4': int,\n",
    "        'feature5': int, 'feature6': int, 'feature7': int, 'feature8': int\n",
    "    },\n",
    ")\n",
    "\n",
    "node_feature_dict = {}\n",
    "for index, row in enumerate(node_features_df.values.tolist()):\n",
    "    node_id, feature1, feature2, feature3, feature4, \\\n",
    "               feature5, feature6, feature7, feature8 = row\n",
    "    # TODO: NaN\n",
    "    features = [feature1, feature2, feature3, feature4, feature5, feature6, feature7, feature8]\n",
    "    features = list(map(lambda x: x if x != -1 else 0, features))\n",
    "    node_feature_dict[node_id] = features\n",
    "# node_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a24ee-bba9-4017-a15b-6ebc0e85e5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce3d3e6e-ccca-4e65-a38c-7190cf1a8c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99dbf238-c448-47eb-8d6d-72d3c70505b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "[5, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for node_id in source_nodes:\n",
    "    print(node_id)\n",
    "    print(node_feature_dict[node_id])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76888264-a664-410d-a712-281d2777f270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "390a1c25-5cd9-4069-9f83-0a4ba64cd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "edge_type_feature_dict = {}\n",
    "with open(f\"{DATA_DIR}/raw/train/edge_type_features.csv\", mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        row = list(map(lambda x: int(x), row))\n",
    "        edge_type, features = row[0], row[1:]\n",
    "        edge_type_feature_dict[edge_type] = features\n",
    "# edge_type_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4185db-bcb5-4e24-a4bf-e0fa4825038d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e22965-4648-4120-941d-200f6cfae1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b6e0002-5a53-4c15-8acf-28a3c72f7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (date, group) in enumerate(grouped_df):\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    source_nodes = group['src_id']\n",
    "    target_nodes = group['dst_id']\n",
    "    timestamp = group['timestamp']\n",
    "    edge_type_series = group['edge_type']\n",
    "    break\n",
    "# source_nodes = group['src_id']\n",
    "# target_nodes = group['dst_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cae6e42-f920-44d0-9a82-6c9b75d42ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nedge_type_features_df = pd.read_csv(\\n    f\"{DATA_DIR}/raw/train/edge_type_features.csv\", header=None,\\n    names=[\\'edge_type\\', \\'feature1\\', \\'feature2\\', \\'feature3\\'],\\n    dtype={\\'edge_type\\': int, \\'feature1\\': int, \\'feature2\\': int, \\'feature3\\': int},\\n).sort_values(\\'edge_type\\')\\nedge_type_feature_dict = {}\\nfor index, row in enumerate(edge_type_features_df.values.tolist()):\\n    edge_type, feature1, feature2, feature3 = row\\n    edge_type_feature_dict[edge_type] = [feature1, feature2, feature3]\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "edge_type_features_df = pd.read_csv(\n",
    "    f\"{DATA_DIR}/raw/train/edge_type_features.csv\", header=None,\n",
    "    names=['edge_type', 'feature1', 'feature2', 'feature3'],\n",
    "    dtype={'edge_type': int, 'feature1': int, 'feature2': int, 'feature3': int},\n",
    ").sort_values('edge_type')\n",
    "edge_type_feature_dict = {}\n",
    "for index, row in enumerate(edge_type_features_df.values.tolist()):\n",
    "    edge_type, feature1, feature2, feature3 = row\n",
    "    edge_type_feature_dict[edge_type] = [feature1, feature2, feature3]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7fd3b-12b1-4546-a88e-5dbd471f1007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b7339ea-1147-4430-8849-9937eb7045bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        28905\n",
       "1         5776\n",
       "2         5502\n",
       "3         5450\n",
       "4         3784\n",
       "         ...  \n",
       "18322    28905\n",
       "18323    20686\n",
       "18324    28905\n",
       "18325    24861\n",
       "18326    28905\n",
       "Name: dst_id, Length: 18327, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413c982-e578-4561-8751-eb0a254f62fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322380a2-0731-4d3a-b0df-458aa2109c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f75258-80a3-44bb-954f-40f65f41de36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "792620df-de47-4981-b309-6e0d99ddbc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed  raw\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/wsdm-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a44cd-3a0e-49df-9f81-b22f8f78e297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "29740941-fc37-44d5-b0b8-b0d2ce7a53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- edges_train_A.csv ----------------\n",
    "\n",
    "edge_list_df = pd.read_csv(\n",
    "    f\"{DATA_DIR}/raw/train/edges_train_A.csv\", header=None,\n",
    "    names=['src_id', 'dst_id', 'edge_type', 'timestamp'],\n",
    "    dtype={'src_id': int, 'dst_id': int,\n",
    "           'edge_type': int, 'timestamp': int},\n",
    ").sort_values('timestamp')\n",
    "edge_list_df['date'] = edge_list_df['timestamp'].apply(\n",
    "    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d\")\n",
    ")\n",
    "grouped_df = edge_list_df.groupby('date')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7752b1bb-7d15-4fe1-a8a6-74a4455b4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- edge_type_features.csv ----------------\n",
    "\n",
    "edge_type_feature_dict = {}\n",
    "with open(f\"{DATA_DIR}/raw/train/edge_type_features.csv\", mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        row = list(map(lambda x: int(x), row))\n",
    "        edge_type, features = row[0], row[1:]\n",
    "        edge_type_feature_dict[edge_type] = features\n",
    "\n",
    "# ---------------- node_features.csv ----------------\n",
    "\n",
    "node_feature_dict = {}\n",
    "with open(f\"{DATA_DIR}/raw/train/node_features.csv\", mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        row = list(map(lambda x: int(x), row))\n",
    "        node_id, features = row[0], row[1:]\n",
    "        features = list(map(lambda x: x if x != -1 else 0, features))\n",
    "        node_feature_dict[node_id] = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cf63f989-6d5a-4212-89a2-e65095ceecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 16, 32]\n",
      "[179, 15, 70]\n"
     ]
    }
   ],
   "source": [
    "print(edge_type_feature_dict[0])\n",
    "print(edge_type_feature_dict[1])\n",
    "# node_feature_dict\n",
    "# node_feature_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "af83d471-542c-45fc-8c54-f7dac7b2c622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1847]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6385ebb9-90ff-49a7-9992-5ef954278c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "fb07524a-c09d-4ff5-ba1c-f8a5c1ad1ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69908, 69914, 69930, 69931])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_mapper.inverse_transform(list(range(0, max_index + 1))[-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ae41f22a-888e-48af-8404-607255b00dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   30,    72,   106, ..., 69914, 69930, 69931])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_indexes = edge_index_mapper.inverse_transform(list(range(0, max_index + 1))[0:-1])\n",
    "node_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "975b741f-fa3c-4f24-aff8-e02d00c0b6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   30,    72,   106, ..., 69930, 69931, 69947])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_indexes = edge_index_mapper.inverse_transform(list(range(0, max_index + 1)))\n",
    "node_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "800b734c-1336-49f8-bab3-b1b988cc4e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feature_dict[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c7cb6b01-1693-49d4-a660-1e0becbe0b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 86, 0, 0],\n",
       " [5, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 361, 0, 0, 0, 0],\n",
       " [11, 0, 0, 0, 0, 0, 0, 11]]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [node_feature_dict[node_index] for node_index in node_indexes]\n",
    "temp[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8dc224f2-54af-4fdd-9758-3edf68e5e705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1847"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index = np.amax((source_nodes, target_nodes))\n",
    "for index in range(0, max_index + 1):\n",
    "    pass\n",
    "#     edge_index_sorter.inverse_transform(\n",
    "# [1188, 1188, 1188, 1799, 47, 1847, 1098, 967,  895, 1043, 773, 742]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "9e0b640d-c270-4495-9e9c-4c53a8dc869e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 17,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,  86,   0,   0],\n",
       "        [  5,   0,   0,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ...,  67,   0,   0],\n",
       "        [  0,   0,   0,  ..., 141,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(node_features, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a7e461c4-8b19-45b3-8f83-7e499db867b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 17,   0,   0,  ...,   0,   0,   0],\n",
       "        [  0,   0,   0,  ...,  86,   0,   0],\n",
       "        [  5,   0,   0,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ...,  67,   0,   0],\n",
       "        [  0,   0,   0,  ..., 141,   0,   0],\n",
       "        [  0,   0,   0,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "22350053-bef7-4b93-8c5f-ad09633c6e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(group['edge_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2cf1f4e3-775b-43b2-82dc-ccf61a07a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_series = group['edge_type']\n",
    "edge_type_series\n",
    "edge_features = [edge_type_feature_dict[edge_type] for edge_type in edge_type_series]\n",
    "# edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "f6394b13-203a-4dd4-9a1b-79245be938c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import sort_edge_index\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "file_name_list = []\n",
    "for index, (datesort_edge_indexroup) in enumerate(grouped_df):\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    source_nodes = group['src_id']\n",
    "    target_nodes = group['dst_id']\n",
    "    timestamp_series = group['timestamp']\n",
    "    edge_type_series = group['edge_type']\n",
    "    \n",
    "    node_index_mapper = LabelEncoder()  # sorter: compress edge index\n",
    "    node_index_mapper.fit(pd.concat([source_nodes, target_nodes], axis=0))\n",
    "    source_nodes = edge_index_mapper.transform(source_nodes)\n",
    "    target_nodes = edge_index_mapper.transform(target_nodes)\n",
    "\n",
    "    # ------------ edge_index ------------\n",
    "    edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "    \n",
    "    # ------------ node_features ------------\n",
    "    max_index = np.amax((source_nodes, target_nodes))\n",
    "    node_indexes = node_index_mapper.inverse_transform(list(range(0, max_index + 1)))\n",
    "    node_features = [node_feature_dict[node_index] for node_index in node_indexes]\n",
    "    # x = torch.LongTensor(node_features)\n",
    "    x = torch.tensor(node_features, dtype=torch.long)\n",
    "    \n",
    "    # ------------ edge_attr ------------\n",
    "    timestamp = group['timestamp']\n",
    "    edge_type = group['edge_type']\n",
    "    edge_features = [edge_type_feature_dict[edge_type] for edge_type in edge_type_series]\n",
    "    \n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "94aeecb5-ca66-49e7-9daf-906334f94c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20\n",
       "1       151\n",
       "2       237\n",
       "3        69\n",
       "4        33\n",
       "       ... \n",
       "7158     65\n",
       "7159    151\n",
       "7160    242\n",
       "7161    242\n",
       "7162    220\n",
       "Name: edge_type, Length: 7163, dtype: int64"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "7c3e08ee-2d2f-4ea8-8f20-75024819161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1188, 1188, 1188, ..., 1799,   47, 1847])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(source_nodes))\n",
    "source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "68fe13d4-35d7-4b8a-9d44-fb40521355ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import sort_edge_index\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "496a8736-8f18-46c0-8610-11fa608ad1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1188, 1188, 1188,  ..., 1799,   47, 1847],\n",
       "        [1098,  967,  895,  ..., 1043,  773,  742]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "63a701ed-a933-40be-8d96-9e95f1ce4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_edge_index(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0b667eea-0f66-4a6f-b32a-f099e79cacda",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2998703/4023141113.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnode_index_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnode_index_mapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msource_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_index_mapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtarget_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_index_mapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/wsdm-2022-challenge/env/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/wsdm-2022-challenge/env/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/wsdm-2022-challenge/env/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 )\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "node_index_mapper = LabelEncoder()  #\n",
    "node_index_mapper.fit(pd.concat([source_nodes, target_nodes], axis=0))\n",
    "source_nodes = node_index_mapper.transform(source_nodes)\n",
    "target_nodes = node_index_mapper.transform(target_nodes)\n",
    "\n",
    "\n",
    "# source_nodes = torch.tensor(source_nodes, dtype=torch.long)\n",
    "# target_nodes = torch.tensor(target_nodes, dtype=torch.long)\n",
    "\n",
    "# edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "print(edge_index.shape)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "bf099c62-81d6-46ed-b8fb-13e4cdd2a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_index_mapper.inverse_transform(\n",
    "#     [1188, 1188, 1188, 1799, 47, 1847, 1098, 967,  895, 1043, 773, 742]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "73f4c8b2-1893-4e97-b801-cd2a923c7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_index_mapper.transform(\n",
    "#     [45285, 45285, 45285, 68389, 1584, 69947, 41603, 35831, 33586, 39520, 30055, 28905]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "53a916a9-f8c9-4e3a-8c4f-2febaeeaf80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1847"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_index = np.sort(np.concatenate((source_nodes, target_nodes), axis=None))[-1]\n",
    "max_index = np.amax((source_nodes, target_nodes))\n",
    "for index in range(0, max_index + 1):\n",
    "    pass\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "1d36d3c8-d399-443c-b5dc-e20bb09e6e77",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2998703/2382783338.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medge_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "edge_list = torch.cat((source_nodes, target_nodes), dim=1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "67ca07e6-175e-475a-96ce-c4eea9c9fed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1188, 1188, 1188,  ..., 1799,   47, 1847])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_nodes = torch.tensor(source_nodes)\n",
    "source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a7b1d-fc36-4405-a6f5-62f832932fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "85aba97d-1a7d-4933-a2e0-2fe56704c7cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2998703/3756360154.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45696d79-239b-4257-81b5-2cd3b80b8418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_edge_index(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c5b09-db1b-4aae-aabf-c967024c93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
    "\n",
    "node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "target_nodes = group.sess_item_id.values[1:]\n",
    "source_nodes = group.sess_item_id.values[:-1]\n",
    "\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "x = node_features\n",
    "\n",
    "y = torch.FloatTensor([group.label.values[0]])\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce666597-cc87-46a4-9e92-731f5021f136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5a1fa-be44-43e3-8b84-ee7c81b4ff15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031fd48-cba4-43d1-87a1-b780bd7e95a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "43b4f7f6-ad25-4185-8cae-2c0ca9790949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET\n",
      "(__init__) root: ../data/wsdm-2022\n",
      "---------------\n",
      "    process    \n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: Data(x=[3255, 8], edge_index=[2, 18327], edge_attrs=[18327], edge_labels=[18327, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'graph_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2998703/1257807575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DATASET\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLargeGraphDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repositories/wsdm-2022-challenge/env/lib/python3.8/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2998703/1257807575.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# data = torch.load(f\"{self.root}/processed/train/graph_{index}.pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# data = torch.load(osp.join(self.processed_dir, f'data_{index}.pt'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_file_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/wsdm-2022-challenge/env/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/wsdm-2022-challenge/env/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/wsdm-2022-challenge/env/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'graph_0'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import datetime\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from torch_geometric.utils import sort_edge_index\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "\n",
    "class LargeGraphDataset(Dataset):\n",
    "    # https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html\n",
    "    def __init__(self, root=\"../data/wsdm-2022\"):\n",
    "        print(\"(__init__) root:\", root)\n",
    "        self.root = root  # DATA_DIR\n",
    "        # self.processed_paths = f\"{self.root}/processed\"\n",
    "\n",
    "        super().__init__(root)\n",
    "\n",
    "        # DATA_DIR = \"../data/wsdm-2022\"\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        # print(\"--------------------\")\n",
    "        # print(\"processed_file_names\")\n",
    "        # print(\"--------------------\")\n",
    "        # self.processed_paths, self.processed_file_names\n",
    "        date_start = datetime.datetime.strptime(\"20141019\", \"%Y%m%d\")\n",
    "        date_end = datetime.datetime.strptime(\"20170514\", \"%Y%m%d\")\n",
    "        file_name_list = []\n",
    "        for index, date in enumerate(pd.date_range(date_start, date_end)):\n",
    "            file_name_list.append(f'graph_{index}')\n",
    "        # print(\"file_name_list:\", len(file_name_list), file_name_list[0])\n",
    "        return file_name_list\n",
    "\n",
    "    def process(self):\n",
    "        print(\"---------------\")\n",
    "        print(\"    process    \")\n",
    "        print(\"---------------\")\n",
    "        DATA_DIR = self.root\n",
    "\n",
    "        # ---------------- edge_type_features.csv ----------------\n",
    "\n",
    "        edge_type_feature_dict = {}\n",
    "        with open(f\"{DATA_DIR}/raw/train/edge_type_features.csv\", mode='r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                row = list(map(lambda x: int(x), row))\n",
    "                edge_type, features = row[0], row[1:]\n",
    "                edge_type_feature_dict[edge_type] = features\n",
    "\n",
    "        # ---------------- node_features.csv ----------------\n",
    "\n",
    "        node_feature_dict = {}\n",
    "        with open(f\"{DATA_DIR}/raw/train/node_features.csv\", mode='r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                row = list(map(lambda x: int(x), row))\n",
    "                node_id, features = row[0], row[1:]\n",
    "                features = list(map(lambda x: x if x != -1 else 0, features))\n",
    "                node_feature_dict[node_id] = features\n",
    "\n",
    "        # ---------------- edges_train_A.csv ----------------\n",
    "\n",
    "        edge_list_df = pd.read_csv(\n",
    "            f\"{DATA_DIR}/raw/train/edges_train_A.csv\", header=None,\n",
    "            names=['src_id', 'dst_id', 'edge_type', 'timestamp'],\n",
    "            dtype={'src_id': int, 'dst_id': int,\n",
    "                   'edge_type': int, 'timestamp': int},\n",
    "        ).sort_values('timestamp')\n",
    "        edge_list_df['date'] = edge_list_df['timestamp'].apply(\n",
    "            lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d\")\n",
    "        )\n",
    "        grouped_df = edge_list_df.groupby('date')\n",
    "\n",
    "        for index, (date, group) in enumerate(grouped_df):\n",
    "            group = group.reset_index(drop=True)\n",
    "\n",
    "            source_nodes = group['src_id']\n",
    "            target_nodes = group['dst_id']\n",
    "            timestamp_series = group['timestamp']\n",
    "            edge_type_series = group['edge_type']\n",
    "\n",
    "            node_index_mapper = LabelEncoder()  # sorter: compress edge index\n",
    "            # print(pd.concat([source_nodes, target_nodes], axis=0))\n",
    "            node_index_mapper.fit(pd.concat([source_nodes, target_nodes], axis=0))\n",
    "            source_nodes = node_index_mapper.transform(source_nodes)\n",
    "            target_nodes = node_index_mapper.transform(target_nodes)\n",
    "\n",
    "            # ------------ edge_index ------------\n",
    "            edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "            # ------------ node_features ------------\n",
    "            max_index = np.amax((source_nodes, target_nodes))\n",
    "            # print(\"max_index:\", max_index)\n",
    "            node_indexes = node_index_mapper.inverse_transform(list(range(0, max_index + 1)))\n",
    "            node_features = [node_feature_dict[node_index] for node_index in node_indexes]\n",
    "            # x = torch.LongTensor(node_features)\n",
    "            x = torch.tensor(node_features, dtype=torch.long)\n",
    "\n",
    "            # ------------ edge_attrs / edge_labels ------------\n",
    "            edge_attrs = [edge_type_feature_dict[edge_type] for edge_type in edge_type_series]\n",
    "            edge_labels = torch.tensor([timestamp_series, edge_type_series], dtype=torch.long)\n",
    "            edge_labels = edge_labels.transpose(0, 1)\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attrs=edge_attrs, edge_labels=edge_labels)\n",
    "            \n",
    "            \n",
    "            print(\"dataset:\", data) if index == 0 else None\n",
    "\n",
    "            torch.save(data, f\"{self.processed_paths[index]}\")\n",
    "\n",
    "            \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, index):\n",
    "        # data = torch.load(f\"{self.root}/processed/train/graph_{index}.pt\")\n",
    "        # data = torch.load(osp.join(self.processed_dir, f'data_{index}.pt'))\n",
    "        data = torch.load(self.processed_file_names[index])\n",
    "        return data\n",
    "\n",
    "\n",
    "print(\"DATASET\")\n",
    "dataset = LargeGraphDataset()\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9244e7-85e4-4efa-baed-4f1377726e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for index, (date, group) in enumerate(grouped_df):\n",
    "    group = group.reset_index(drop=True)\n",
    "    print(date)\n",
    "    print(group)\n",
    "\n",
    "    source_nodes = group['src_id']\n",
    "    target_nodes = group['dst_id']\n",
    "    edge_type = group['edge_type']\n",
    "    timestamp = group['timestamp']\n",
    "    \n",
    "    edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "    edge_attrs = torch.tensor([edge_type, timestamp], dtype=torch.long)\n",
    "    edge_attrs = edge_attrs.transpose(0, 1)\n",
    "    \n",
    "    print(edge_index.shape)\n",
    "    print(edge_attrs.shape)\n",
    "\n",
    "    data = Data(edge_index=edge_index, edge_attrs=edge_attrs)\n",
    "    data_list.append(data)\n",
    "    if index > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a8521-6db2-439f-b9d8-979ed03261ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad41033-a245-4c94-982d-b986252dc722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ff17d-f6ec-4860-940e-f4812930b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff12d2-91e2-417e-8bc0-a7ce0282f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/wsdm-2022\"\n",
    "\n",
    "print(\"FILES\")\n",
    "print(sorted(os.listdir(f\"{DATA_DIR}/train\")))\n",
    "print(sorted(os.listdir(f\"{DATA_DIR}/test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb7b26-9283-4386-b7b7-7335ecc41a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = pd.read_csv(\n",
    "    f\"{DATA_DIR}/train/edges_train_A.csv\",\n",
    "    header=None,\n",
    "    names=['src_id', 'dst_id', 'edge_type', 'timestamp'],\n",
    "    dtype={'src_id': int, 'dst_id': int, 'edge_type': int, 'timestamp': int},\n",
    ").sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d4a61-2299-4ace-b9bd-f92fc3ef3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ededf370-f594-4866-88f9-95a3a98b499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2372f6c5-32f6-4d78-977d-90a52db85e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.from_pandas_edgelist(\n",
    "    edge_list[:200],\n",
    "    source='src_id', target='dst_id',\n",
    "    edge_attr=True,\n",
    "    create_using=nx.DiGraph()\n",
    ")\n",
    "DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453f8a5-50e2-47e6-b6bd-7888af079006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, text\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "fig.set_tight_layout(False)\n",
    "\n",
    "pos = nx.kamada_kawai_layout(DG)\n",
    "# pos = nx.spring_layout(DG)\n",
    "# pos = nx.fruchterman_reingold_layout(G)  # TOO SLOW\n",
    "\n",
    "nx.draw(\n",
    "    DG, pos,\n",
    "    node_size=50,\n",
    "    # with_labels=True,\n",
    "    \n",
    ")\n",
    "for node, (x, y) in pos.items():\n",
    "    text(x, y, node, fontsize=5, ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087380f-0292-4560-ae78-9205dc50c580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a5a8e-5758-4bc1-885c-c9dea5b78947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78488da3-53ee-4eee-bc65-2418a42e449d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba501e5-0cea-4d0d-99aa-08a8ad779bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "edge_list_org = edge_list.copy()\n",
    "edge_list = edge_list[:30000]\n",
    "print(len(edge_list), len(edge_list_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd6f97-0bb6-4c87-b3ab-a7cf8f963ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.DiGraph()\n",
    "G = nx.from_pandas_edgelist(edge_list, 'src_id', 'dst_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64458e-4556-48d3-bd12-20a6f023722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(10, 8))\n",
    "# nx.draw_shell(G, with_labels=True)\n",
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263c89b-2392-4e66-82a5-9ac615bb1adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7f0f9-8a96-4c94-a60c-75c24ad51558",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_tight_layout(False)\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "# pos = nx.fruchterman_reingold_layout(G)\n",
    "nx.draw(G, pos, with_labels=True)\n",
    "# nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbf7fa-46ec-4ad5-bcd7-dbc673ec3ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed82a5-89fc-4143-8d28-1530e4ff2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def plot_degree_dist(G):\n",
    "    degrees = [G.degree(n) for n in G.nodes()]\n",
    "    plt.hist(\n",
    "        degrees,\n",
    "        bins=100,\n",
    "        log=True,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "plot_degree_dist(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121bc90-5202-44f2-940f-6342ded2459a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5adf14-210d-462c-9720-5915b1173b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network()\n",
    "for index, row in edge_list.iterrows():\n",
    "    net.add_node(row['src_id'], label=row['src_id'])\n",
    "    net.add_node(row['dst_id'], label=row['dst_id'])\n",
    "    net.add_edge(row['src_id'], row['dst_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c39e1f-d6c6-4f9c-b901-b258f156465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.show('nodes.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19338e6b-8880-4a0a-ab63-fc5488f48597",
   "metadata": {},
   "source": [
    "<img src=\"../assets/pyvis_network_2022_0103_01.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb387f-5b89-4fe2-be83-8b38455671f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12638d23-8088-4aac-9da6-9febbc526bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e36c2-c17a-4fcf-9fe0-14c851385b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b3f30-f639-4b75-b1ec-5c886ac9db84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c3a1a-5548-4390-a195-350ddaead5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2268a01-6a7c-41ec-a17b-a2c39c6ef7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de62814-b183-406b-baa9-939d5f056b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41b2e5c7-f218-4820-b9c1-a0db4c58013c",
   "metadata": {},
   "source": [
    "### EDGE TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f8a6a-15c6-4669-8b9e-4223d5f0a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = edge_list['timestamp'].copy()\n",
    "datetimes = timestamps.apply(\n",
    "    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "dates = timestamps.apply(\n",
    "    lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y%m%d\")\n",
    ")\n",
    "edge_list['datetime'] = datetimes\n",
    "edge_list['date'] = dates\n",
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9b9cb-61bf-4f7c-b05e-750ee49214d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list['edge_type'].value_counts().plot(\n",
    "    kind='bar', figsize=(10,6), title=\"Edge Type Frequency\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b61a4-f0e7-4c53-956d-44d8d7aeea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_list['edge_type'].value_counts()[:10].sum())\n",
    "edge_list['edge_type'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee042d2a-2383-4770-8a33-ec5c6b665f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_count = edge_list.groupby(['date', 'edge_type']).size()\n",
    "edge_type_count = edge_type_count.reset_index(name='count')\n",
    "edge_type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca8eda9-3b37-4cbe-97e2-0edce42c8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10\n",
    "\n",
    "top_10_edge_type = list(edge_list['edge_type'].value_counts()[:10].index)\n",
    "top_10_edge_list = edge_list[edge_list['edge_type'].isin(top_10_edge_type)]\n",
    "top_10_edge_list_count = top_10_edge_list.groupby(['date', 'edge_type'])\n",
    "top_10_edge_list_count = top_10_edge_list_count.size().reset_index(name='count')\n",
    "top_10_edge_list_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4703e9a-a00b-4c3f-b733-ca0bcd4f08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "sns.pointplot(\n",
    "    x='date',\n",
    "    y='count',\n",
    "    hue='edge_type',\n",
    "    # dashes= False,\n",
    "    # marker='^',\n",
    "    # color='pastel',\n",
    "    # alpha=0.8,\n",
    "    ax=axes,\n",
    "    # data=data,\n",
    "    data=top_10_edge_list_count,\n",
    ")\n",
    "\n",
    "start, end = axes.get_xlim()\n",
    "axes.xaxis.set_ticks(np.arange(start, end, 20))\n",
    "for tick in axes.get_xticklabels():\n",
    "    tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa892de7-8377-4daa-a58c-5bef5348961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ed376-e5ac-4b89-8367-a8ef1020f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "sns.pointplot(\n",
    "    x='timestamp',\n",
    "    y='count',\n",
    "    hue='edge_type',\n",
    "    # dashes= False,\n",
    "    # marker='^',\n",
    "    # color='pastel',\n",
    "    # alpha=0.8,\n",
    "    ax=axes,\n",
    "    # data=data,\n",
    "    data=edge_list,\n",
    ")\n",
    "\n",
    "start, end = axes.get_xlim()\n",
    "axes.xaxis.set_ticks(np.arange(start, end, 20))\n",
    "for tick in axes.get_xticklabels():\n",
    "    tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab756c-d016-49ba-bbd5-75933ab38e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59f0a4-f71b-44b8-9056-a536b20d14bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f81f3b-e298-4203-a0f9-d69cbb8796a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3929b-e937-4040-90bc-42cf8f06f45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
